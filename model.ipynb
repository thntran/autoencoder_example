{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "mount_file_id": "1yfQsR0I9BJLKChNBhbrO_YJx-uQUTTWH",
      "authorship_tag": "ABX9TyMGULaTguKbN/whV0/BUoMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshimelaine/autoencoder_example/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHB1H-eahczj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed0e3fe7-cab7-44e5-c1e9-a883412d2d85"
      },
      "source": [
        "import copy\n",
        "from keras import backend as K\n",
        "from keras import objectives\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Lambda\n",
        "from keras.layers.core import Dense, Activation, Flatten, RepeatVector\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.layers.convolutional import Convolution1D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGnyfVOohnka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoleculeVAE():\n",
        "\n",
        "    autoencoder = None\n",
        "    \n",
        "    def create(self,\n",
        "               charset,\n",
        "               max_length = 120,\n",
        "               latent_rep_size = 292,\n",
        "               weights_file = None):\n",
        "        charset_length = len(charset)\n",
        "        \n",
        "        x = Input(shape=(max_length, charset_length))\n",
        "        _, z = self._buildEncoder(x, latent_rep_size, max_length)\n",
        "        self.encoder = Model(x, z)\n",
        "\n",
        "        encoded_input = Input(shape=(latent_rep_size,))\n",
        "        self.decoder = Model(\n",
        "            encoded_input,\n",
        "            self._buildDecoder(\n",
        "                encoded_input,\n",
        "                latent_rep_size,\n",
        "                max_length,\n",
        "                charset_length\n",
        "            )\n",
        "        )\n",
        "\n",
        "        x1 = Input(shape=(max_length, charset_length))\n",
        "        vae_loss, z1 = self._buildEncoder(x1, latent_rep_size, max_length)\n",
        "        self.autoencoder = Model(\n",
        "            x1,\n",
        "            self._buildDecoder(\n",
        "                z1,\n",
        "                latent_rep_size,\n",
        "                max_length,\n",
        "                charset_length\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if weights_file:\n",
        "            self.autoencoder.load_weights(weights_file)\n",
        "            self.encoder.load_weights(weights_file, by_name = True)\n",
        "            self.decoder.load_weights(weights_file, by_name = True)\n",
        "\n",
        "        self.autoencoder.compile(optimizer = 'Adam',\n",
        "                                 loss = vae_loss,\n",
        "                                 metrics = ['accuracy'])\n",
        "\n",
        "    def _buildEncoder(self, x, latent_rep_size, max_length, epsilon_std = 0.01):\n",
        "        h = Convolution1D(9, 9, activation = 'relu', name='conv_1')(x)\n",
        "        h = Convolution1D(9, 9, activation = 'relu', name='conv_2')(h)\n",
        "        h = Convolution1D(10, 11, activation = 'relu', name='conv_3')(h)\n",
        "        h = Flatten(name='flatten_1')(h)\n",
        "        h = Dense(435, activation = 'relu', name='dense_1')(h)\n",
        "\n",
        "        def sampling(args):\n",
        "            z_mean_, z_log_var_ = args\n",
        "            batch_size = K.shape(z_mean_)[0]\n",
        "            epsilon = K.random_normal(shape=(batch_size, latent_rep_size), mean=0., stddev = epsilon_std)\n",
        "            return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n",
        "\n",
        "        z_mean = Dense(latent_rep_size, name='z_mean', activation = 'linear')(h)\n",
        "        z_log_var = Dense(latent_rep_size, name='z_log_var', activation = 'linear')(h)\n",
        "\n",
        "        def vae_loss(x, x_decoded_mean):\n",
        "            x = K.flatten(x)\n",
        "            x_decoded_mean = K.flatten(x_decoded_mean)\n",
        "            xent_loss = max_length * objectives.binary_crossentropy(x, x_decoded_mean)\n",
        "            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis = -1)\n",
        "            return xent_loss + kl_loss\n",
        "\n",
        "        return (vae_loss, Lambda(sampling, output_shape=(latent_rep_size,), name='lambda')([z_mean, z_log_var]))\n",
        "\n",
        "    def _buildDecoder(self, z, latent_rep_size, max_length, charset_length):\n",
        "        h = Dense(latent_rep_size, name='latent_input', activation = 'relu')(z)\n",
        "        h = RepeatVector(max_length, name='repeat_vector')(h)\n",
        "        h = GRU(501, return_sequences = True, name='gru_1')(h)\n",
        "        h = GRU(501, return_sequences = True, name='gru_2')(h)\n",
        "        h = GRU(501, return_sequences = True, name='gru_3')(h)\n",
        "        return TimeDistributed(Dense(charset_length, activation='softmax'), name='decoded_mean')(h)\n",
        "\n",
        "    def save(self, filename):\n",
        "        self.autoencoder.save_weights(filename)\n",
        "    \n",
        "    def load(self, charset, weights_file, latent_rep_size = 292):\n",
        "        self.create(charset, weights_file = weights_file, latent_rep_size = latent_rep_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}